{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b429e6d2-101b-45df-9958-85b10e8aa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05efae22-ca7c-44df-9bf2-8551c74d9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/momoka/miniconda3/envs/othello/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "# make deterministic\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796b304f-0f64-46d4-ae69-b03553c08034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data import get_othello, plot_probs, plot_mentals\n",
    "from data.othello import permit, start_hands, OthelloBoardState, permit_reverse\n",
    "from mingpt.dataset import CharDataset\n",
    "from mingpt.model import GPT, GPTConfig, GPTforProbeIA\n",
    "from mingpt.utils import sample, intervene, print_board\n",
    "from mingpt.probe_model import BatteryProbeClassification, BatteryProbeClassificationTwoLayer\n",
    "\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', **{'size': 14.0})\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{lmodern}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837026e8-1834-4a9b-ae5b-4a6ff857c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "championship = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be98be3c-f484-4a15-bbe9-a640ecb37bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_dim = 128\n",
    "how_many_history_step_to_use = 99\n",
    "exp = f\"state_tl{mid_dim}\"\n",
    "if championship:\n",
    "    exp += \"_championship\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71378fe3-d9c2-401a-b1a0-9445f6ffd242",
   "metadata": {},
   "source": [
    "## Load a game from intervention benchmark and select an intervention configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de77e19-451a-4f3b-89fd-4efdba144882",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"intervention_benchmark.pkl\", \"rb\") as input_file:\n",
    "    dataset = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e08851-7508-4a56-993a-0f67be5ecb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intervention_position': 'e6', 'intervention_from': 2.0, 'intervention_to': 0.0}\n"
     ]
    }
   ],
   "source": [
    "case_id = 777\n",
    "wtd = {\n",
    "    \"intervention_position\": permit_reverse(dataset[case_id][\"pos_int\"]), \n",
    "    \"intervention_from\": dataset[case_id][\"ori_color\"], \n",
    "    \"intervention_to\": 2 - dataset[case_id][\"ori_color\"], \n",
    "}\n",
    "completion = dataset[case_id][\"history\"]\n",
    "print(wtd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0944ee4b-452a-4d83-a4ff-8bafb2cc0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd_list = [wtd]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89df37-9dea-4261-94e4-b602ec8cfffb",
   "metadata": {},
   "source": [
    "## Load nonlinear probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e85d97-4f7a-4c90-99b2-9b04cae1154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = {}\n",
    "layer_s = 4\n",
    "layer_e = 1\n",
    "for layer in range(layer_s, layer_e):\n",
    "    p = BatteryProbeClassificationTwoLayer(torch.cuda.current_device(), probe_class=3, num_task=64, mid_dim=mid_dim)\n",
    "    load_res = p.load_state_dict(torch.load(f\"./ckpts/battery_othello/{exp}/layer{layer}/checkpoint.ckpt\"))\n",
    "    p.eval()\n",
    "    probes[layer] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96259d73-16a9-4ec2-94e2-1dbc294648b3",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d0f8a5-b06b-454e-a1b2-a97d719f3d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5e373cf0ba35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# othello = get_othello(ood_perc=.2, data_root=\"data/othello_pgn\", wthor=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mothello\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_othello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mood_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwthor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mothello\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m61\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m59\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_head\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_embd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/h/382/momoka/othello_world/data/othello.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(ood_perc, data_root, wthor, ood_num)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mood_perc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwthor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mOthello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mood_perc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mOthelloBoardState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/h/382/momoka/othello_world/data/othello.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ood_perc, data_root, wthor, ood_num)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mood_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# this setting used for generating synthetic dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mnum_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use all processors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_ood_game\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mood_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mood_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36mPool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m'''Returns a process pool object'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         return Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0m\u001b[1;32m    120\u001b[0m                     context=self.get_context())\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repopulate_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return self._repopulate_pool_static(self._ctx, self.Process,\n\u001b[0m\u001b[1;32m    304\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inqueue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PoolWorker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'added worker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/othello/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mchild_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "# othello = get_othello(ood_perc=.2, data_root=\"data/othello_pgn\", wthor=False)\n",
    "othello = get_othello(ood_perc=0., data_root=None, wthor=False, ood_num=1)\n",
    "train_dataset = CharDataset(othello)\n",
    "\n",
    "mconf = GPTConfig(61, 59, n_layer=8, n_head=8, n_embd=512)\n",
    "\n",
    "models = {}\n",
    "for layer in range(layer_s, layer_e):\n",
    "    model = GPTforProbeIA(mconf, probe_layer=layer)\n",
    "    # model = GPT(mconf)\n",
    "    load_res = model.load_state_dict(torch.load(\"./ckpts/gpt_synthetic.ckpt\" if not championship else \"./ckpts/gpt_championship.ckpt\"))\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.cuda.current_device()\n",
    "        model = model.to(device)\n",
    "    _ = model.eval()\n",
    "    models[layer] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc45bc-e369-44f4-bc5e-54bfec187825",
   "metadata": {},
   "source": [
    "### Check the partial game progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90954b-6e49-4b63-9dca-5851c748ba54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = OthelloBoardState()\n",
    "ab.update(completion, prt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd21ce5-6c66-419f-a4d0-2a5c12896862",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_game = torch.tensor([train_dataset.stoi[s] for s in completion], dtype=torch.long).to(device)\n",
    "partial_game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e84e85-9c75-402c-9026-6dee99e4db46",
   "metadata": {},
   "source": [
    "### Check pre-intervention ground-truth legal next-steps and the predicted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0c20c-895c-4385-bb69-0ff45e39715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "pre_intv_valids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9b4d1-5fd5-48db-add4-fa03305ad661",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_intv_pred, _ = model(partial_game[None, :])  # [B, T, F=512]\n",
    "# no history activations used here, that's why the prediction map is different to across layers\n",
    "pre_intv_pred = pre_intv_pred[0, -1, 1:]\n",
    "padding = torch.zeros(2).cuda()\n",
    "pre_intv_pred = torch.softmax(pre_intv_pred, dim=0)\n",
    "pre_intv_pred = torch.cat([pre_intv_pred[:27], padding, pre_intv_pred[27:33], padding, pre_intv_pred[33:]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71efd0e-2614-41d5-9ac0-7d9bdf212c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "vv = 0.2\n",
    "sns.heatmap(pre_intv_pred.detach().cpu().numpy().reshape(8, 8), vmin=0., vmax=vv, \n",
    "            yticklabels=list(\"ABCDEFGH\"), xticklabels=list(range(1,9)), square=True, \n",
    "            annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e559c0-78b1-4114-af0f-521db6b7107d",
   "metadata": {},
   "source": [
    "## Check post-intervention ground-truth next steps\n",
    "0 for white; 1 for blank; 2 for black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c0a8c-8746-4089-a888-bb28fa1aaf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "htd = {\"lr\": 1e-3, \"steps\": 1000, \"reg_strg\": 0.2}\n",
    "for wtd in wtd_list:\n",
    "    move = permit(wtd[\"intervention_position\"])\n",
    "    r, c = move // 8, move % 8\n",
    "    ab.state[r, c] = wtd[\"intervention_to\"] - 1\n",
    "ab.__print__()\n",
    "post_intv_valids = [permit_reverse(_) for _ in ab.get_valid_moves()]\n",
    "post_intv_valids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bd486f-ec23-4700-bf5a-9d85eed8813d",
   "metadata": {},
   "source": [
    "## Intervene and observe how the world representation changes along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef294d-ad0b-4256-bd16-0ef533250e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(layer_e - layer_s, 2, figsize=(8 * (1), 8 * (layer_e - layer_s)), dpi= 80, facecolor='w', edgecolor='k')\n",
    "# two rows for the intervened layer layer_s, one for the rest\n",
    "if len(axs.shape) == 1:\n",
    "    axs = axs[:, None]\n",
    "\n",
    "p = probes[layer_s]\n",
    "whole_mid_act = models[layer_s].forward_1st_stage(partial_game[None, :])  # [B, T, F=512]\n",
    "\n",
    "# intervene at the earlest interested layer \n",
    "mid_act = whole_mid_act[0, -1]\n",
    "pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "plot_mentals(axs[0, 0], pre_intv_logits)\n",
    "axs[0, 0].set_title(f\"Pre-intervention Probe Result \\n at the {layer_s}-th Layer\")\n",
    "labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "new_mid_act = mid_act.clone()\n",
    "for wtd in wtd_list:\n",
    "    new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "    pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "post_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "plot_mentals(axs[0, 1], post_intv_logits)\n",
    "axs[0, 1].set_title(f\"Post-intervention Probe Result \\n at the {layer_s}-th Layer\")\n",
    "# swap in \n",
    "whole_mid_act[0, -1] = new_mid_act\n",
    "\n",
    "for i, layer in enumerate(range(layer_s, layer_e - 1)):  # 4, 5, 6, 7, indices of the layers to be passed\n",
    "    p = probes[layer+1]\n",
    "    whole_mid_act = models[layer_s].forward_2nd_stage(whole_mid_act, layer, layer+1)[0]  # [1, T, F=512]\n",
    "    \n",
    "    # intervene the output of the features freshly out\n",
    "    mid_act = whole_mid_act[0, -1]\n",
    "    pre_intv_logits = p(mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    plot_mentals(axs[i+1, 0], pre_intv_logits)\n",
    "    axs[i+1, 0].set_title(f\"Post-intervention Probe Result \\n at the {layer+1}-th Layer\")\n",
    "    labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    new_mid_act = mid_act.clone()\n",
    "    for wtd in wtd_list:\n",
    "        new_mid_act = intervene(p, new_mid_act, labels_pre_intv, wtd, htd, plot=True)\n",
    "        pre_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "        labels_pre_intv = pre_intv_logits.detach().argmax(dim=-1)\n",
    "    post_intv_logits = p(new_mid_act[None, :])[0].squeeze(0)  # [64, 3]\n",
    "    plot_mentals(axs[i+1, 1], post_intv_logits)\n",
    "    axs[i+1, 1].set_title(f\"Post-intervention Probe Result \\n at the {layer+1}-th Layer\")\n",
    "    # swap in \n",
    "    whole_mid_act[0, -1] = new_mid_act"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b931979c-6224-42e9-8756-3b04706a0091",
   "metadata": {},
   "source": [
    "## Compare post-intervention prediction heatmap with pre-intervention ones\n",
    "Underscored tiles are the ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529ff1c-b645-477f-ab71-b42ee4eb5546",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6), dpi= 80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plot_probs(axs[0], pre_intv_pred, [permit(_) for _ in pre_intv_valids])\n",
    "axs[0].set_title(f\"Pre-intervention Prediction Heatmap\")\n",
    "\n",
    "tb_resumed = whole_mid_act\n",
    "post_intv_pred, _ = models[layer_s].predict(tb_resumed)\n",
    "post_intv_pred = post_intv_pred[0, -1, 1:]\n",
    "post_intv_pred = torch.softmax(post_intv_pred, dim=0)\n",
    "post_intv_pred = torch.cat([post_intv_pred[:27], padding, post_intv_pred[27:33], padding, post_intv_pred[33:]], dim=0)\n",
    "\n",
    "plot_probs(axs[1], post_intv_pred, [permit(_) for _ in post_intv_valids])\n",
    "axs[1].set_title(f\"Post-intervention Prediction Heatmap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "othello",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
